"""
AgentæœåŠ¡ - æ•´åˆDeepSeek APIå’ŒMCPå·¥å…·è°ƒç”¨
æ”¯æŒå¤šä¸“å®¶ Plan and Execute æ¨¡å¼
"""

import json
import logging
from typing import Dict, List, Any, Optional, Tuple
from datetime import datetime
import mysql.connector
from deepseek_client import DeepSeekClient
from mcp_client import MCPClient
from session_manager import SessionManager
from config import MYSQL_CONFIG
from expert_system import Planner, Executor

logger = logging.getLogger(__name__)

class AgentService:
    """AgentæœåŠ¡ç±»"""
    
    def __init__(self, use_expert_mode: bool = True):
        self.deepseek_client = DeepSeekClient()
        self.mcp_client = MCPClient()
        self.session_manager = SessionManager()
        # ç”¨äºè·Ÿè¸ªthinkingæ ‡ç­¾çŠ¶æ€
        self._in_thinking = False
        self._thinking_complete = False
        
        # å¤šä¸“å®¶æ¨¡å¼ - é»˜è®¤å¯ç”¨ (Plan-and-Execute + ReAct æ··åˆæ¶æ„)
        self.use_expert_mode = use_expert_mode
        if use_expert_mode:
            self.planner = Planner(self.deepseek_client)
            self.executor = Executor(self.deepseek_client, self.mcp_client, planner=self.planner)
            logger.info("ğŸ¤– å¤šä¸“å®¶æ¨¡å¼å·²å¯ç”¨ (Plan-and-Execute + ReAct æ··åˆæ¶æ„)")
        else:
            logger.info("ğŸ“ ä½¿ç”¨æ ‡å‡†å•Agentæ¨¡å¼")
        
    async def get_user_info(self, user_id: int) -> Optional[Dict[str, Any]]:
        """
        è·å–ç”¨æˆ·ä¿¡æ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            ç”¨æˆ·ä¿¡æ¯å­—å…¸
        """
        try:
            mysql_conn = mysql.connector.connect(**MYSQL_CONFIG)
            cursor = mysql_conn.cursor(dictionary=True)
            
            cursor.execute("""
                SELECT id, username, real_name, email, phone, gender, user_type, status
                FROM sys_user 
                WHERE id = %s AND is_deleted = 0
            """, (user_id,))
            
            user_info = cursor.fetchone()
            
            cursor.close()
            mysql_conn.close()
            
            return user_info
            
        except Exception as e:
            logger.error(f"è·å–ç”¨æˆ·ä¿¡æ¯å¤±è´¥: {e}")
            return None
    
    async def process_message(self, user_id: int, message: str) -> Dict[str, Any]:
        """
        å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            å¤„ç†ç»“æœ
        """
        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = await self.get_user_info(user_id)
            if not user_info:
                return {
                    "success": False,
                    "error": "ç”¨æˆ·ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"
                }
            
            # è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆMongoDB + Redisï¼‰
            session_id = await self.session_manager.get_or_create_session(user_id, user_info)
            logger.info(f"ğŸ“‹ å½“å‰ä¼šè¯ID: {session_id}")
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            await self.session_manager.add_message(user_id, "user", message)
            
            # è·å–å¯¹è¯å†å²
            conversation_history = await self.session_manager.get_conversation_history(user_id, limit=10)
            
            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [self.deepseek_client.build_system_message(user_info)]
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆæ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰
            for msg in conversation_history:
                if msg["role"] != "system":
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user", 
                "content": message
            })
            
            # è·å–MCPå·¥å…·schema
            tool_schemas = self.mcp_client.get_tool_schemas()
            formatted_tools = self.deepseek_client.format_tools_for_api(tool_schemas)
            
            # è°ƒç”¨DeepSeek API
            response = await self.deepseek_client.chat_completion(
                messages=messages,
                tools=formatted_tools
            )
            
            if not response["success"]:
                return {
                    "success": False,
                    "error": f"AIè°ƒç”¨å¤±è´¥: {response.get('error')}"
                }
            
            ai_message = response["message"]
            
            # å¤„ç†å·¥å…·è°ƒç”¨
            if ai_message.get("tool_calls"):
                tool_results = []
                
                for tool_call in ai_message["tool_calls"]:
                    tool_name = tool_call["function"]["name"]
                    try:
                        tool_args = json.loads(tool_call["function"]["arguments"])
                    except json.JSONDecodeError:
                        tool_args = {}
                    
                    # è°ƒç”¨MCPå·¥å…·
                    tool_result = await self.mcp_client.call_tool(tool_name, tool_args)
                    tool_results.append({
                        "tool_call_id": tool_call["id"],
                        "tool_name": tool_name,
                        "result": tool_result
                    })
                
                # å¦‚æœæœ‰å·¥å…·è°ƒç”¨ï¼Œéœ€è¦å†æ¬¡è°ƒç”¨AIæ¥ç”Ÿæˆæœ€ç»ˆå›å¤
                
                # â­ é‡è¦ï¼šæå–ç¬¬ä¸€æ¬¡assistantæ¶ˆæ¯ä¸­çš„thinkingå†…å®¹ï¼Œç¨åä¸æœ€ç»ˆå›å¤åˆå¹¶ä¿å­˜
                first_content = ai_message["content"] or ""
                first_thinking_content = ""
                if first_content:
                    logger.info(f"ğŸ“ æå–ç¬¬ä¸€æ¬¡æ¶ˆæ¯ä¸­çš„thinkingå†…å®¹ï¼Œæ¶ˆæ¯é•¿åº¦: {len(first_content)}")
                    first_thinking_content, _ = self._extract_thinking_from_complete_content(first_content)
                    if first_thinking_content:
                        logger.info(f"âœ… æå–åˆ°thinkingå†…å®¹ï¼Œé•¿åº¦: {len(first_thinking_content)}")
                
                # æ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                messages.append({
                    "role": "assistant",
                    "content": first_content,
                    "tool_calls": ai_message["tool_calls"]
                })
                
                # æ·»åŠ å·¥å…·ç»“æœ
                for tool_result in tool_results:
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_result["tool_call_id"],
                        "content": json.dumps(tool_result["result"], ensure_ascii=False)
                    })
                
                # å†æ¬¡è°ƒç”¨AIè·å–æœ€ç»ˆå›å¤
                logger.info(f"å‡†å¤‡è¿›è¡Œæœ€ç»ˆAIè°ƒç”¨ï¼Œæ¶ˆæ¯æ•°é‡: {len(messages)}")
                final_response = await self.deepseek_client.chat_completion(
                    messages=messages,
                    tools=formatted_tools
                )
                
                logger.info(f"æœ€ç»ˆAIè°ƒç”¨ç»“æœ: success={final_response.get('success')}")
                
                if final_response["success"]:
                    ai_message = final_response["message"]
                    response_content = ai_message.get("content", "")
                    
                    logger.info(f"æœ€ç»ˆå›å¤å†…å®¹é•¿åº¦: {len(response_content) if response_content else 0}")
                    
                    # æ£€æŸ¥å›å¤å†…å®¹
                    if not response_content or response_content.strip() == "":
                        logger.warning("AIè¿”å›äº†ç©ºçš„å›å¤å†…å®¹ï¼Œç”Ÿæˆå¤‡ç”¨å›å¤")
                        # ç”Ÿæˆå¤‡ç”¨åˆ†æå›å¤
                        response_content = self._generate_fallback_analysis(tool_results)
                    
                    # ğŸ”„ åˆå¹¶ä¿å­˜ï¼šå°†ç¬¬ä¸€æ¬¡æ¶ˆæ¯çš„thinkingä¸æœ€ç»ˆå›å¤åˆå¹¶
                    logger.info(f"ğŸ’¾ åˆå¹¶ä¿å­˜å®Œæ•´å›å¤ï¼Œå†…å®¹é•¿åº¦: {len(response_content)}")
                    
                    # æ£€æŸ¥æœ€ç»ˆå›å¤ä¸­æ˜¯å¦ä¹Ÿæœ‰thinkingï¼ˆç½•è§æƒ…å†µï¼‰
                    final_thinking_content, clean_final_content = self._extract_thinking_from_complete_content(response_content)
                    
                    # åˆå¹¶thinkingå†…å®¹ï¼šä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€æ¬¡æ¶ˆæ¯çš„thinkingï¼Œè¡¥å……æœ€ç»ˆå›å¤çš„thinking
                    combined_thinking = first_thinking_content
                    if final_thinking_content:
                        logger.info(f"âš ï¸ æœ€ç»ˆå›å¤ä¸­ä¹ŸåŒ…å«thinkingï¼Œé•¿åº¦: {len(final_thinking_content)}")
                        if combined_thinking:
                            combined_thinking += "\n\n" + final_thinking_content
                        else:
                            combined_thinking = final_thinking_content
                    
                    # ä½¿ç”¨æœ€ç»ˆå›å¤çš„clean content
                    final_content = clean_final_content or response_content
                    
                    logger.info(f"ğŸ“Š åˆå¹¶ç»“æœ - thinkingé•¿åº¦: {len(combined_thinking) if combined_thinking else 0}, contenté•¿åº¦: {len(final_content)}")
                    
                    await self.session_manager.add_message(
                        user_id, 
                        "assistant", 
                        final_content,
                        tool_results,
                        combined_thinking
                    )
                    
                    return {
                        "success": True,
                        "response": response_content,
                        "tool_calls": tool_results,
                        "usage": final_response.get("usage", {})
                    }
                else:
                    logger.error(f"AIæœ€ç»ˆå›å¤å¤±è´¥: {final_response.get('error')}")
                    # ç”Ÿæˆå¤‡ç”¨å›å¤
                    fallback_response = self._generate_fallback_analysis(tool_results)
                    
                    # ğŸ”„ fallbackæƒ…å†µä¸‹ä¹Ÿéœ€è¦åˆå¹¶thinkingå†…å®¹
                    logger.info(f"ğŸ’¾ åˆå¹¶ä¿å­˜fallbackå›å¤ï¼Œå†…å®¹é•¿åº¦: {len(fallback_response)}")
                    
                    fallback_thinking_content, clean_fallback_content = self._extract_thinking_from_complete_content(fallback_response)
                    
                    # åˆå¹¶thinkingå†…å®¹ï¼šä¼˜å…ˆä½¿ç”¨ç¬¬ä¸€æ¬¡æ¶ˆæ¯çš„thinking
                    combined_thinking = first_thinking_content
                    if fallback_thinking_content:
                        logger.info(f"âš ï¸ fallbackå›å¤ä¸­ä¹ŸåŒ…å«thinkingï¼Œé•¿åº¦: {len(fallback_thinking_content)}")
                        if combined_thinking:
                            combined_thinking += "\n\n" + fallback_thinking_content
                        else:
                            combined_thinking = fallback_thinking_content
                    
                    logger.info(f"ğŸ“Š fallbackåˆå¹¶ç»“æœ - thinkingé•¿åº¦: {len(combined_thinking) if combined_thinking else 0}, contenté•¿åº¦: {len(clean_fallback_content)}")
                    
                    await self.session_manager.add_message(
                        user_id, 
                        "assistant", 
                        clean_fallback_content,
                        tool_results,
                        combined_thinking
                    )
                    
                    return {
                        "success": True,
                        "response": fallback_response,
                        "tool_calls": tool_results,
                        "usage": {}
                    }
            
            else:
                # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥è¿”å›AIå›å¤
                thinking_content, clean_content = self._extract_thinking_from_complete_content(ai_message["content"])
                logger.info(f"ğŸ’¾ ä¿å­˜AIæ¶ˆæ¯ - thinkingé•¿åº¦: {len(thinking_content) if thinking_content else 0}, contenté•¿åº¦: {len(clean_content)}")
                if thinking_content:
                    logger.info(f"ğŸ’¾ thinkingå†…å®¹é¢„è§ˆ: {thinking_content[:50]}...")
                await self.session_manager.add_message(user_id, "assistant", clean_content, thinking=thinking_content)
                
                return {
                    "success": True,
                    "response": ai_message["content"],
                    "tool_calls": [],
                    "usage": response.get("usage", {})
                }
                
        except Exception as e:
            logger.error(f"å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def process_message_stream(self, user_id: int, message: str, session_id: str = None):
        """
        æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: å¯é€‰çš„ä¼šè¯IDï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æŒ‡å®šä¼šè¯ï¼Œå¦åˆ™è‡ªåŠ¨è·å–æˆ–åˆ›å»º
            
        Yields:
            æµå¼å“åº”æ•°æ®
        """
        try:
            # é‡ç½®thinkingçŠ¶æ€
            self._in_thinking = False
            self._thinking_complete = False
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = await self.get_user_info(user_id)
            if not user_info:
                yield {
                    "type": "error",
                    "error": "ç”¨æˆ·ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"
                }
                return
            
            # è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆä¸å¤šä¸“å®¶æ¨¡å¼ä¸€è‡´ï¼‰
            if session_id:
                # å¦‚æœæä¾›äº†session_idï¼Œè®¾ç½®å®ƒä¸ºå½“å‰ä¼šè¯
                logger.info(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šä¼šè¯ID: {session_id}")
                await self.session_manager.set_current_session(user_id, session_id, user_info)
            else:
                # å¦åˆ™è‡ªåŠ¨è·å–æˆ–åˆ›å»ºæ–°ä¼šè¯
                session_id = await self.session_manager.get_or_create_session(user_id, user_info)
                logger.info(f"ğŸ“‹ è‡ªåŠ¨è·å–/åˆ›å»ºä¼šè¯ID: {session_id}")
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            await self.session_manager.add_message(user_id, "user", message)
            
            # è·å–å¯¹è¯å†å²
            conversation_history = await self.session_manager.get_conversation_history(user_id, limit=10)
            
            # æ„å»ºå¯¹è¯æ¶ˆæ¯
            messages = [self.deepseek_client.build_system_message(user_info)]
            
            # æ·»åŠ å†å²å¯¹è¯ï¼ˆæ’é™¤ç³»ç»Ÿæ¶ˆæ¯ï¼‰
            for msg in conversation_history:
                if msg["role"] != "system":
                    messages.append({
                        "role": msg["role"],
                        "content": msg["content"]
                    })
            
            # æ·»åŠ å½“å‰ç”¨æˆ·æ¶ˆæ¯
            messages.append({
                "role": "user", 
                "content": message
            })
            
            # è·å–MCPå·¥å…·schema
            tool_schemas = self.mcp_client.get_tool_schemas()
            formatted_tools = self.deepseek_client.format_tools_for_api(tool_schemas)
            
            # æµå¼è°ƒç”¨DeepSeek API
            accumulated_content = ""
            tool_calls = []
            
            async for chunk in self.deepseek_client.chat_completion_stream(
                messages=messages,
                tools=formatted_tools
            ):
                if chunk.get("type") == "error":
                    yield chunk
                    return
                
                elif chunk.get("type") == "content":
                    # å®æ—¶å‘é€å†…å®¹å¢é‡
                    accumulated_content = chunk["accumulated_content"]
                    
                    # æ£€æµ‹æ€è€ƒè¿‡ç¨‹å¹¶å•ç‹¬å‘é€
                    thinking_content, clean_content = self._extract_thinking_from_stream(
                        chunk["content"], accumulated_content
                    )
                    
                    if thinking_content:
                        yield {
                            "type": "thinking",
                            "content": thinking_content
                        }
                    
                    if clean_content:
                        yield {
                            "type": "content", 
                            "content": clean_content
                        }
                
                elif chunk.get("type") == "tool_call_start":
                    yield {
                        "type": "tool_call_start", 
                        "tool_name": chunk["tool_name"]
                    }
                
                elif chunk.get("type") == "tool_calls_complete":
                    # å¤„ç†å·¥å…·è°ƒç”¨
                    tool_calls = chunk["tool_calls"]
                    yield {
                        "type": "tools_start",
                        "message": f"æ­£åœ¨è°ƒç”¨ {len(tool_calls)} ä¸ªå·¥å…·..."
                    }
                    
                    tool_results = []
                    for tool_call in tool_calls:
                        tool_name = tool_call["function"]["name"]
                        try:
                            tool_args = json.loads(tool_call["function"]["arguments"])
                        except json.JSONDecodeError:
                            tool_args = {}
                        
                        yield {
                            "type": "tool_executing",
                            "tool_name": tool_name
                        }
                        
                        # è°ƒç”¨MCPå·¥å…·
                        tool_result = await self.mcp_client.call_tool(tool_name, tool_args)
                        tool_results.append({
                            "tool_call_id": tool_call["id"],
                            "tool_name": tool_name,
                            "result": tool_result
                        })
                        
                        yield {
                            "type": "tool_complete",
                            "tool_name": tool_name,
                            "result": tool_result
                        }
                    
                    # æ·»åŠ å·¥å…·è°ƒç”¨æ¶ˆæ¯åˆ°å¯¹è¯å†å²
                    messages.append({
                        "role": "assistant",
                        "content": accumulated_content or "",
                        "tool_calls": tool_calls
                    })
                    
                    # æ·»åŠ å·¥å…·ç»“æœ
                    for tool_result in tool_results:
                        messages.append({
                            "role": "tool",
                            "tool_call_id": tool_result["tool_call_id"],
                            "content": json.dumps(tool_result["result"], ensure_ascii=False)
                        })
                    
                    yield {
                        "type": "final_response_start",
                        "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›å¤..."
                    }
                    
                    # é€’å½’å¤„ç†å¯èƒ½çš„å¤šè½®å·¥å…·è°ƒç”¨
                    final_tool_results = tool_results
                    final_messages = messages.copy()
                    max_tool_rounds = 100  # æœ€å¤šå…è®¸100è½®å·¥å…·è°ƒç”¨ï¼ˆå®é™…ä¸Šå‡ ä¹ä¸å—é™åˆ¶ï¼‰
                    tool_round = 0
                    
                    while tool_round < max_tool_rounds:
                        tool_round += 1
                        logger.info(f"ğŸ”„ å·¥å…·è°ƒç”¨è½®æ¬¡: {tool_round}")
                        
                        # å†æ¬¡æµå¼è°ƒç”¨AIè·å–æœ€ç»ˆå›å¤
                        final_content = ""
                        final_thinking_buffer = ""  # ç´¯ç§¯thinkingå†…å®¹
                        final_thinking_complete = False
                        final_in_thinking = False
                        has_more_tools = False
                        
                        async for final_chunk in self.deepseek_client.chat_completion_stream(
                            messages=final_messages,
                            tools=formatted_tools
                        ):
                            if final_chunk.get("type") == "content":
                                final_content = final_chunk["accumulated_content"]
                                chunk_content = final_chunk["content"]
                                
                                # ä»æœ€ç»ˆå›å¤ä¸­åˆ†ç¦»thinkingå†…å®¹å¹¶å®æ—¶å‘é€
                                thinking_part, clean_part = self._extract_thinking_from_final_stream(
                                    chunk_content, final_thinking_buffer, final_thinking_complete, final_in_thinking
                                )
                                
                                # æ›´æ–°çŠ¶æ€
                                if thinking_part["thinking_content"]:
                                    final_thinking_buffer += thinking_part["thinking_content"]
                                    yield {
                                        "type": "thinking",
                                        "content": thinking_part["thinking_content"]
                                    }
                                
                                final_thinking_complete = thinking_part["thinking_complete"]
                                final_in_thinking = thinking_part["in_thinking"]
                                
                                # åªå‘é€éthinkingçš„å†…å®¹éƒ¨åˆ†
                                if clean_part:
                                    yield {
                                        "type": "final_content",
                                        "content": clean_part
                                    }
                            
                            elif final_chunk.get("type") == "tool_calls_complete":
                                # æ£€æµ‹åˆ°æ›´å¤šå·¥å…·è°ƒç”¨
                                has_more_tools = True
                                additional_tool_calls = final_chunk["tool_calls"]
                                
                                logger.info(f"ğŸ”„ ç¬¬{tool_round}è½®æ£€æµ‹åˆ°æ›´å¤šå·¥å…·è°ƒç”¨: {len(additional_tool_calls)}ä¸ª")
                                
                                yield {
                                    "type": "tools_start",
                                    "message": f"ç»§ç»­è°ƒç”¨ {len(additional_tool_calls)} ä¸ªå·¥å…·..."
                                }
                                
                                # æ‰§è¡Œé¢å¤–çš„å·¥å…·è°ƒç”¨
                                additional_results = []
                                for tool_call in additional_tool_calls:
                                    tool_name = tool_call["function"]["name"]
                                    try:
                                        tool_args = json.loads(tool_call["function"]["arguments"])
                                    except json.JSONDecodeError:
                                        tool_args = {}
                                    
                                    yield {
                                        "type": "tool_executing",
                                        "tool_name": tool_name
                                    }
                                    
                                    # è°ƒç”¨MCPå·¥å…·
                                    tool_result = await self.mcp_client.call_tool(tool_name, tool_args)
                                    additional_results.append({
                                        "tool_call_id": tool_call["id"],
                                        "tool_name": tool_name,
                                        "result": tool_result
                                    })
                                    
                                    yield {
                                        "type": "tool_complete",
                                        "tool_name": tool_name,
                                        "result": tool_result
                                    }
                                
                                # æ›´æ–°å·¥å…·ç»“æœå’Œæ¶ˆæ¯å†å²
                                final_tool_results.extend(additional_results)
                                
                                # æ·»åŠ åˆ°æ¶ˆæ¯å†å²
                                final_messages.append({
                                    "role": "assistant",
                                    "content": final_content or "",
                                    "tool_calls": additional_tool_calls
                                })
                                
                                for tool_result in additional_results:
                                    final_messages.append({
                                        "role": "tool",
                                        "tool_call_id": tool_result["tool_call_id"],
                                        "content": json.dumps(tool_result["result"], ensure_ascii=False)
                                    })
                                
                                break  # è·³å‡ºå†…å±‚å¾ªç¯ï¼Œç»§ç»­ä¸‹ä¸€è½®
                            
                            elif final_chunk.get("type") == "complete":
                                final_content = final_chunk["content"]
                                break
                            
                            elif final_chunk.get("type") == "error":
                                # å¦‚æœæœ€ç»ˆå›å¤å¤±è´¥ï¼Œç”Ÿæˆå¤‡ç”¨å›å¤
                                final_content = self._generate_fallback_analysis(final_tool_results)
                                yield {
                                    "type": "final_content",
                                    "content": final_content
                                }
                                break
                        
                        # å¦‚æœæ²¡æœ‰æ›´å¤šå·¥å…·è°ƒç”¨ï¼Œç»“æŸå¾ªç¯
                        if not has_more_tools:
                            break
                    
                    # ä¿å­˜AIå›å¤ - éœ€è¦åˆå¹¶æ‰€æœ‰thinkingå†…å®¹
                    # 1. ä»ç¬¬ä¸€æ¬¡æ¶ˆæ¯ä¸­æå–thinkingï¼ˆå·¥å…·è°ƒç”¨å‰çš„æ€è€ƒï¼‰
                    first_thinking_content, _ = self._extract_thinking_from_complete_content(accumulated_content or "")
                    
                    # 2. ä»æœ€ç»ˆå›å¤ä¸­æå–thinkingï¼ˆå·¥å…·è°ƒç”¨åçš„æ€è€ƒï¼‰
                    final_thinking_content, clean_final_content = self._extract_thinking_from_complete_content(final_content)
                    
                    # 3. åˆå¹¶æ‰€æœ‰thinkingå†…å®¹
                    combined_thinking = ""
                    if first_thinking_content:
                        combined_thinking = first_thinking_content
                        logger.info(f"ğŸ§  ç¬¬ä¸€æ¬¡thinkingé•¿åº¦: {len(first_thinking_content)}")
                    
                    if final_thinking_content:
                        if combined_thinking:
                            combined_thinking += "\n\n" + final_thinking_content
                        else:
                            combined_thinking = final_thinking_content
                        logger.info(f"ğŸ§  æœ€ç»ˆthinkingé•¿åº¦: {len(final_thinking_content)}")
                    
                    # 4. ä½¿ç”¨æœ€ç»ˆçš„clean content
                    final_clean_content = clean_final_content or final_content
                    
                    logger.info(f"ğŸ”„ WebSocketå·¥å…·æµç¨‹å®Œæˆ - å·¥å…·è½®æ¬¡: {tool_round}, æ€»å·¥å…·æ•°: {len(final_tool_results)}, thinkingé•¿åº¦: {len(combined_thinking) if combined_thinking else 0}")
                    
                    await self.session_manager.add_message(
                        user_id, 
                        "assistant", 
                        final_clean_content,
                        final_tool_results,
                        combined_thinking
                    )
                    
                    yield {
                        "type": "complete",
                        "final_response": final_content,
                        "tool_calls": final_tool_results
                    }
                    return
                
                elif chunk.get("type") == "complete":
                    # æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œç›´æ¥å®Œæˆ
                    final_content = chunk["content"]
                    thinking_content, clean_content = self._extract_thinking_from_complete_content(final_content)
                    logger.info(f"ğŸ æµå¼å®Œæˆ - thinkingé•¿åº¦: {len(thinking_content) if thinking_content else 0}, contenté•¿åº¦: {len(clean_content)}")
                    if thinking_content:
                        logger.info(f"ğŸ thinkingå†…å®¹é¢„è§ˆ: {thinking_content[:50]}...")
                    await self.session_manager.add_message(user_id, "assistant", clean_content, thinking=thinking_content)
                    
                    yield {
                        "type": "complete",
                        "final_response": final_content,
                        "tool_calls": []
                    }
                    return
                    
        except Exception as e:
            logger.error(f"æµå¼å¤„ç†æ¶ˆæ¯å¤±è´¥: {e}")
            yield {
                "type": "error",
                "error": str(e)
            }
    
    def _generate_fallback_analysis(self, tool_results: List[Dict[str, Any]]) -> str:
        """
        ç”Ÿæˆå¤‡ç”¨åˆ†æå›å¤ï¼ˆå½“AIè°ƒç”¨å¤±è´¥æ—¶ä½¿ç”¨ï¼‰
        
        Args:
            tool_results: å·¥å…·è°ƒç”¨ç»“æœåˆ—è¡¨
            
        Returns:
            å¤‡ç”¨åˆ†æå›å¤æ–‡æœ¬
        """
        try:
            analysis_parts = []
            action_type = "query"  # é»˜è®¤ä¸ºæŸ¥è¯¢ç±»å‹
            
            for tool_result in tool_results:
                tool_name = tool_result.get("tool_name", "")
                result_data = tool_result.get("result", {})
                
                if not result_data.get("success", False):
                    continue
                
                data = result_data.get("data", {})
                
                if tool_name == "query_user_health_records":
                    analysis_parts.append(self._analyze_health_records(data))
                elif tool_name == "add_health_record":
                    action_type = "add"  # æ ‡è®°ä¸ºæ·»åŠ æ“ä½œ
                    analysis_parts.append(self._analyze_added_record(data))
                elif tool_name == "query_doctor_list":
                    analysis_parts.append(self._analyze_doctor_list(data))
                else:
                    # é€šç”¨æ•°æ®åˆ†æ
                    if isinstance(data, dict) and data:
                        analysis_parts.append(f"ğŸ“Š {tool_name}æŸ¥è¯¢ç»“æœï¼š\n{self._format_data_summary(data)}")
            
            if analysis_parts:
                if action_type == "add":
                    # å¯¹äºæ·»åŠ æ“ä½œï¼Œä½¿ç”¨ç®€æ´çš„å›å¤
                    return "\n\n".join(analysis_parts)
                else:
                    # å¯¹äºæŸ¥è¯¢æ“ä½œï¼Œä½¿ç”¨åˆ†ææ€§å›å¤
                    return "æ ¹æ®æ•°æ®æŸ¥è¯¢ç»“æœï¼Œæˆ‘ä¸ºæ‚¨è¿›è¡Œä»¥ä¸‹åˆ†æï¼š\n\n" + "\n\n".join(analysis_parts)
            else:
                return "æ“ä½œå·²å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹çš„ç»“æœã€‚"
                
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤‡ç”¨åˆ†æå¤±è´¥: {e}")
            return "æ•°æ®æŸ¥è¯¢å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹çš„æŸ¥è¯¢ç»“æœã€‚"
    
    def _analyze_health_records(self, data: Dict[str, Any]) -> str:
        """åˆ†æå¥åº·è®°å½•æ•°æ®"""
        try:
            if not data or "records" not in data:
                return "ğŸ“Š å¥åº·è®°å½•æŸ¥è¯¢å®Œæˆï¼Œä½†æœªæ‰¾åˆ°ç›¸å…³æ•°æ®ã€‚"
            
            records = data["records"]
            total_count = data.get("total_count", 0)
            
            if not records:
                return f"ğŸ“Š å¥åº·è®°å½•åˆ†æï¼šç›®å‰å…±æœ‰{total_count}æ¡è®°å½•ï¼Œä½†æŸ¥è¯¢æ—¶é—´èŒƒå›´å†…æ— æ•°æ®ã€‚å»ºè®®æ‰©å¤§æŸ¥è¯¢æ—¶é—´èŒƒå›´ã€‚"
            
            analysis = f"ğŸ“Š **å¥åº·è®°å½•åˆ†æ**ï¼ˆå…±{total_count}æ¡è®°å½•ï¼‰ï¼š\n\n"
            
            # æŒ‰ç±»å‹åˆ†ç»„åˆ†æ
            glucose_records = [r for r in records if r.get("type") == "glucose"]
            pressure_records = [r for r in records if r.get("type") == "pressure"]
            weight_records = [r for r in records if r.get("type") == "weight"]
            
            if glucose_records:
                latest_glucose = glucose_records[0]
                value = latest_glucose.get("value", 0)
                measure_type = latest_glucose.get("measureType", "")
                
                analysis += f"ğŸ©¸ **è¡€ç³–æƒ…å†µ**ï¼š\n"
                analysis += f"- æœ€æ–°è®°å½•ï¼š{value} mmol/L ({measure_type})\n"
                
                if value < 3.9:
                    analysis += "- âš ï¸ è¡€ç³–åä½ï¼Œå»ºè®®åŠæ—¶è¡¥å……è‘¡è„ç³–\n"
                elif value > 7.8:
                    analysis += "- âš ï¸ è¡€ç³–åé«˜ï¼Œå»ºè®®æ³¨æ„é¥®é£Ÿæ§åˆ¶\n"
                else:
                    analysis += "- âœ… è¡€ç³–æ°´å¹³æ­£å¸¸\n"
                
                analysis += f"- è®°å½•æ•°é‡ï¼š{len(glucose_records)}æ¡\n\n"
            
            if pressure_records:
                analysis += f"ğŸ’“ **è¡€å‹è®°å½•**ï¼š{len(pressure_records)}æ¡è®°å½•\n\n"
            
            if weight_records:
                analysis += f"âš–ï¸ **ä½“é‡è®°å½•**ï¼š{len(weight_records)}æ¡è®°å½•\n\n"
            
            analysis += "ğŸ’¡ **å»ºè®®**ï¼šä¿æŒè§„å¾‹ç›‘æµ‹ï¼Œå¦‚æœ‰å¼‚å¸¸è¯·åŠæ—¶å’¨è¯¢åŒ»ç”Ÿã€‚"
            
            return analysis
            
        except Exception as e:
            logger.error(f"åˆ†æå¥åº·è®°å½•å¤±è´¥: {e}")
            return "ğŸ“Š å¥åº·è®°å½•æŸ¥è¯¢å®Œæˆï¼Œè¯·æŸ¥çœ‹ä¸Šæ–¹æ•°æ®è¯¦æƒ…ã€‚"
    
    def _analyze_added_record(self, data: Dict[str, Any]) -> str:
        """åˆ†ææ–°æ·»åŠ çš„å¥åº·è®°å½•"""
        try:
            if not data or not data.get("success"):
                return "âŒ å¥åº·è®°å½•æ·»åŠ å¤±è´¥ã€‚"
            
            record_details = data.get("record_details", {})
            record_type = record_details.get("type", "")
            record_data = record_details.get("data", {})
            
            if record_type == "glucose":
                value = record_data.get("value", 0)
                measure_type = record_data.get("measureType", "")
                return f"âœ… è¡€ç³–è®°å½•æ·»åŠ æˆåŠŸï¼š{value} mmol/L ({measure_type})"
            elif record_type == "pressure":
                systolic = record_data.get("systolic", 0)
                diastolic = record_data.get("diastolic", 0)
                return f"âœ… è¡€å‹è®°å½•æ·»åŠ æˆåŠŸï¼š{systolic}/{diastolic} mmHg"
            elif record_type == "weight":
                weight = record_data.get("weight", record_data.get("value", 0))
                return f"âœ… ä½“é‡è®°å½•æ·»åŠ æˆåŠŸï¼š{weight} kg"
            else:
                return f"âœ… å¥åº·è®°å½•æ·»åŠ æˆåŠŸ"
                
        except Exception as e:
            logger.error(f"åˆ†ææ–°å¢è®°å½•å¤±è´¥: {e}")
            return "âœ… å¥åº·è®°å½•å·²æ·»åŠ "
    
    def _analyze_doctor_list(self, data: Dict[str, Any]) -> str:
        """åˆ†æåŒ»ç”Ÿåˆ—è¡¨æ•°æ®"""
        try:
            doctors = data.get("doctors", [])
            if not doctors:
                return "ğŸ“‹ åŒ»ç”ŸæŸ¥è¯¢å®Œæˆï¼Œä½†å½“å‰æ— å¯ç”¨åŒ»ç”Ÿã€‚"
            
            available_count = len([d for d in doctors if d.get("is_online")])
            total_count = len(doctors)
            
            return f"ğŸ‘¨â€âš•ï¸ **åŒ»ç”Ÿåˆ—è¡¨åˆ†æ**ï¼š\n- å…±æ‰¾åˆ°{total_count}ä½åŒ»ç”Ÿ\n- å½“å‰åœ¨çº¿ï¼š{available_count}ä½\n- å»ºè®®é€‰æ‹©åœ¨çº¿åŒ»ç”Ÿè¿›è¡Œå’¨è¯¢"
            
        except Exception as e:
            logger.error(f"åˆ†æåŒ»ç”Ÿåˆ—è¡¨å¤±è´¥: {e}")
            return "ğŸ‘¨â€âš•ï¸ åŒ»ç”Ÿåˆ—è¡¨æŸ¥è¯¢å®Œæˆã€‚"
    
    def _format_data_summary(self, data: Dict[str, Any]) -> str:
        """æ ¼å¼åŒ–æ•°æ®æ‘˜è¦"""
        try:
            if isinstance(data, dict):
                summary_parts = []
                for key, value in data.items():
                    if isinstance(value, (list, dict)):
                        summary_parts.append(f"- {key}: {len(value) if isinstance(value, list) else 'å¤æ‚å¯¹è±¡'}é¡¹")
                    else:
                        summary_parts.append(f"- {key}: {value}")
                return "\n".join(summary_parts[:5])  # é™åˆ¶æ˜¾ç¤ºå‰5é¡¹
            else:
                return str(data)[:200] + "..." if len(str(data)) > 200 else str(data)
                
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–æ•°æ®æ‘˜è¦å¤±è´¥: {e}")
            return "æ•°æ®æ ¼å¼å¤æ‚ï¼Œè¯·æŸ¥çœ‹è¯¦ç»†ç»“æœã€‚"
    
    def _extract_thinking_from_stream(self, chunk_content: str, accumulated_content: str) -> Tuple[str, str]:
        """
        ä»æµå¼å†…å®¹ä¸­æå–æ€è€ƒè¿‡ç¨‹
        
        Args:
            chunk_content: å½“å‰chunkçš„å†…å®¹
            accumulated_content: ç´¯ç§¯çš„å†…å®¹
            
        Returns:
            tuple: (thinking_content, clean_content)
        """
        thinking_content = ""
        clean_content = ""
        
        try:
            # å¦‚æœä¹‹å‰æ²¡æœ‰å®Œæˆthinkingï¼Œç»§ç»­æ£€æµ‹
            if not self._thinking_complete:
                # æ£€æµ‹thinkingå¼€å§‹æ ‡ç­¾
                if not self._in_thinking and "<thinking>" in chunk_content:
                    self._in_thinking = True
                    # æå–thinkingå¼€å§‹åçš„å†…å®¹
                    thinking_start = chunk_content.find("<thinking>") + len("<thinking>")
                    remaining_content = chunk_content[thinking_start:]
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€chunkä¸­ç»“æŸ
                    if "</thinking>" in remaining_content:
                        thinking_end = remaining_content.find("</thinking>")
                        thinking_content = remaining_content[:thinking_end]
                        self._thinking_complete = True
                        self._in_thinking = False
                        
                        # æ¸…ç†åçš„å†…å®¹æ˜¯</thinking>ä¹‹åçš„éƒ¨åˆ†
                        clean_content = remaining_content[thinking_end + len("</thinking>"):]
                        return thinking_content, clean_content
                    else:
                        # thinkingè·¨å¤šä¸ªchunkï¼Œç«‹å³è¿”å›å½“å‰éƒ¨åˆ†
                        thinking_content = remaining_content
                        # ä¸è¿”å›æ™®é€šå†…å®¹ï¼Œå› ä¸ºéƒ½åœ¨thinkingä¸­
                        return thinking_content, ""
                
                # å¦‚æœæ­£åœ¨thinkingä¸­
                elif self._in_thinking:
                    if "</thinking>" in chunk_content:
                        # thinkingç»“æŸ
                        thinking_end = chunk_content.find("</thinking>")
                        thinking_part = chunk_content[:thinking_end]
                        self._thinking_complete = True
                        self._in_thinking = False
                        
                        # æ¸…ç†åçš„å†…å®¹æ˜¯</thinking>ä¹‹åçš„éƒ¨åˆ†
                        clean_content = chunk_content[thinking_end + len("</thinking>"):]
                        return thinking_part, clean_content
                    else:
                        # ç»§ç»­è¿”å›thinkingå†…å®¹çš„å½“å‰chunk
                        thinking_content = chunk_content
                        return thinking_content, ""
                
                # æ²¡æœ‰thinkingæ ‡ç­¾ï¼Œæ­£å¸¸è¿”å›å†…å®¹
                else:
                    return "", chunk_content
            
            # thinkingå·²å®Œæˆï¼Œæ­£å¸¸è¿”å›å†…å®¹
            else:
                return "", chunk_content
                
        except Exception as e:
            logger.error(f"æå–thinkingå¤±è´¥: {e}")
            # å‡ºé”™æ—¶è¿”å›åŸå§‹å†…å®¹
            return "", chunk_content
    
    def _extract_thinking_from_final_stream(self, chunk_content: str, thinking_buffer: str, 
                                          thinking_complete: bool, in_thinking: bool) -> tuple[Dict[str, Any], str]:
        """
        ä»æœ€ç»ˆå›å¤æµä¸­æå–thinkingå†…å®¹ï¼ˆå·¥å…·è°ƒç”¨åé˜¶æ®µä¸“ç”¨ï¼‰
        
        Args:
            chunk_content: å½“å‰chunkçš„å†…å®¹
            thinking_buffer: ç´¯ç§¯çš„thinkingå†…å®¹
            thinking_complete: thinkingæ˜¯å¦å·²å®Œæˆ
            in_thinking: æ˜¯å¦åœ¨thinkingä¸­
            
        Returns:
            tuple: (thinking_info_dict, clean_content)
        """
        result_thinking = {
            "thinking_content": "",
            "thinking_complete": thinking_complete,
            "in_thinking": in_thinking
        }
        
        try:
            # å¦‚æœthinkingè¿˜æ²¡å®Œæˆï¼Œç»§ç»­æ£€æµ‹
            if not thinking_complete:
                # æ£€æµ‹thinkingå¼€å§‹æ ‡ç­¾
                if not in_thinking and "<thinking>" in chunk_content:
                    result_thinking["in_thinking"] = True
                    # æå–thinkingå¼€å§‹åçš„å†…å®¹
                    thinking_start = chunk_content.find("<thinking>") + len("<thinking>")
                    remaining_content = chunk_content[thinking_start:]
                    
                    # æ£€æŸ¥æ˜¯å¦åœ¨åŒä¸€chunkä¸­ç»“æŸ
                    if "</thinking>" in remaining_content:
                        thinking_end = remaining_content.find("</thinking>")
                        result_thinking["thinking_content"] = remaining_content[:thinking_end]
                        result_thinking["thinking_complete"] = True
                        result_thinking["in_thinking"] = False
                        
                        # æ¸…ç†åçš„å†…å®¹æ˜¯</thinking>ä¹‹åçš„éƒ¨åˆ†
                        clean_content = remaining_content[thinking_end + len("</thinking>"):]
                        return result_thinking, clean_content
                    else:
                        # thinkingè·¨å¤šä¸ªchunk
                        result_thinking["thinking_content"] = remaining_content
                        return result_thinking, ""
                
                # å¦‚æœæ­£åœ¨thinkingä¸­
                elif in_thinking:
                    if "</thinking>" in chunk_content:
                        # thinkingç»“æŸ
                        thinking_end = chunk_content.find("</thinking>")
                        result_thinking["thinking_content"] = chunk_content[:thinking_end]
                        result_thinking["thinking_complete"] = True
                        result_thinking["in_thinking"] = False
                        
                        # æ¸…ç†åçš„å†…å®¹æ˜¯</thinking>ä¹‹åçš„éƒ¨åˆ†
                        clean_content = chunk_content[thinking_end + len("</thinking>"):]
                        return result_thinking, clean_content
                    else:
                        # ç»§ç»­è¿”å›thinkingå†…å®¹çš„å½“å‰chunk
                        result_thinking["thinking_content"] = chunk_content
                        return result_thinking, ""
                
                # æ²¡æœ‰thinkingæ ‡ç­¾ï¼Œæ­£å¸¸è¿”å›å†…å®¹
                else:
                    return result_thinking, chunk_content
            
            # thinkingå·²å®Œæˆï¼Œæ­£å¸¸è¿”å›å†…å®¹
            else:
                return result_thinking, chunk_content
                
        except Exception as e:
            logger.error(f"æå–æœ€ç»ˆå›å¤thinkingå¤±è´¥: {e}")
            # å‡ºé”™æ—¶è¿”å›åŸå§‹å†…å®¹
            return result_thinking, chunk_content
    
    def _extract_thinking_from_complete_content(self, content: str) -> tuple[str, str]:
        """
        ä»å®Œæ•´å†…å®¹ä¸­åˆ†ç¦»thinkingå’Œclean content
        
        Args:
            content: åŒ…å«thinkingæ ‡ç­¾çš„å®Œæ•´å†…å®¹
            
        Returns:
            tuple: (thinking_content, clean_content)
        """
        import re
        
        logger.info(f"ğŸ” å¼€å§‹æå–thinkingå†…å®¹ï¼ŒåŸå§‹å†…å®¹é•¿åº¦: {len(content)}")
        logger.info(f"ğŸ” åŸå§‹å†…å®¹é¢„è§ˆ: {content[:200]}...")
        
        # æŸ¥æ‰¾thinkingæ ‡ç­¾
        thinking_match = re.search(r'<thinking>(.*?)</thinking>', content, re.DOTALL | re.IGNORECASE)
        
        if thinking_match:
            thinking_content = thinking_match.group(1).strip()
            # ç§»é™¤thinkingéƒ¨åˆ†ï¼Œå¾—åˆ°å¹²å‡€çš„å†…å®¹
            clean_content = re.sub(r'<thinking>.*?</thinking>', '', content, flags=re.DOTALL | re.IGNORECASE).strip()
            logger.info(f"âœ… æ‰¾åˆ°thinkingå†…å®¹ï¼Œé•¿åº¦: {len(thinking_content)}")
            logger.info(f"âœ… thinkingå†…å®¹é¢„è§ˆ: {thinking_content[:100]}...")
            return thinking_content, clean_content
        else:
            logger.warning(f"âŒ æœªæ‰¾åˆ°thinkingæ ‡ç­¾ï¼Œå†…å®¹å°†ä½œä¸ºæ™®é€šcontentä¿å­˜")
            return "", content
    
    async def get_conversation_history(self, user_id: int, limit: int = 20) -> Dict[str, Any]:
        """
        è·å–å¯¹è¯å†å²
        
        Args:
            user_id: ç”¨æˆ·ID
            limit: æ¶ˆæ¯æ•°é‡é™åˆ¶
            
        Returns:
            å¯¹è¯å†å²
        """
        try:
            user_info = await self.get_user_info(user_id)
            if not user_info:
                return {
                    "success": False,
                    "error": "ç”¨æˆ·ä¸å­˜åœ¨"
                }
            
            messages = await self.session_manager.get_conversation_history(user_id, limit)
            
            # è½¬æ¢å­—æ®µåä»¥åŒ¹é…å‰ç«¯æœŸæœ›çš„æ ¼å¼ï¼ˆé©¼å³° -> è›‡å½¢ï¼‰
            formatted_messages = []
            for msg in messages:
                formatted_msg = {
                    "role": msg.get("role"),
                    "content": msg.get("content"),
                    "timestamp": msg.get("timestamp")
                }
                
                # è½¬æ¢ toolCalls -> tool_calls
                if "toolCalls" in msg:
                    formatted_msg["tool_calls"] = msg["toolCalls"]
                elif "tool_calls" in msg:
                    formatted_msg["tool_calls"] = msg["tool_calls"]
                
                # è½¬æ¢ thinking å­—æ®µ
                if "thinking" in msg:
                    formatted_msg["thinking"] = msg["thinking"]
                
                # è½¬æ¢ expertPlan -> expert_plan
                if "expertPlan" in msg:
                    formatted_msg["expert_plan"] = msg["expertPlan"]
                elif "expert_plan" in msg:
                    formatted_msg["expert_plan"] = msg["expert_plan"]
                
                formatted_messages.append(formatted_msg)
            
            return {
                "success": True,
                "user_info": user_info,
                "messages": formatted_messages,
                "total_messages": len(formatted_messages)
            }
            
        except Exception as e:
            logger.error(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def clear_conversation(self, user_id: int) -> Dict[str, Any]:
        """
        æ¸…é™¤å¯¹è¯å†å²
        
        Args:
            user_id: ç”¨æˆ·ID
            
        Returns:
            æ“ä½œç»“æœ
        """
        try:
            await self.session_manager.clear_session(user_id)
            return {
                "success": True,
                "message": "å¯¹è¯å†å²å·²æ¸…é™¤"
            }
            
        except Exception as e:
            logger.error(f"æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {e}")
            return {
                "success": False,
                "error": str(e)
            }
    
    async def process_message_expert_stream(self, user_id: int, message: str, session_id: str = None):
        """
        ä½¿ç”¨å¤šä¸“å®¶æ¨¡å¼æµå¼å¤„ç†ç”¨æˆ·æ¶ˆæ¯
        
        Args:
            user_id: ç”¨æˆ·ID
            message: ç”¨æˆ·æ¶ˆæ¯
            session_id: å¯é€‰çš„ä¼šè¯IDï¼Œå¦‚æœæä¾›åˆ™ä½¿ç”¨æŒ‡å®šä¼šè¯ï¼Œå¦åˆ™è‡ªåŠ¨è·å–æˆ–åˆ›å»º
            
        Yields:
            æµå¼å“åº”æ•°æ®
        """
        try:
            # è·å–ç”¨æˆ·ä¿¡æ¯
            user_info = await self.get_user_info(user_id)
            if not user_info:
                yield {
                    "type": "error",
                    "error": "ç”¨æˆ·ä¸å­˜åœ¨æˆ–å·²è¢«åˆ é™¤"
                }
                return
            
            # è·å–æˆ–åˆ›å»ºä¼šè¯ï¼ˆMongoDB + Redisï¼‰
            if session_id:
                # å¦‚æœæä¾›äº†session_idï¼Œè®¾ç½®å®ƒä¸ºå½“å‰ä¼šè¯
                logger.info(f"ğŸ“‹ ä½¿ç”¨æŒ‡å®šä¼šè¯ID: {session_id}")
                await self.session_manager.set_current_session(user_id, session_id, user_info)
            else:
                # å¦åˆ™è‡ªåŠ¨è·å–æˆ–åˆ›å»ºæ–°ä¼šè¯
                session_id = await self.session_manager.get_or_create_session(user_id, user_info)
                logger.info(f"ğŸ“‹ è‡ªåŠ¨è·å–/åˆ›å»ºä¼šè¯ID: {session_id}")
            
            # ä¿å­˜ç”¨æˆ·æ¶ˆæ¯
            await self.session_manager.add_message(user_id, "user", message)
            
            # è·å–å†å²å¯¹è¯è®°å½•ï¼ˆåŒ…æ‹¬åˆšä¿å­˜çš„ç”¨æˆ·æ¶ˆæ¯ï¼‰
            conversation_history = await self.session_manager.get_conversation_history(user_id, limit=10)
            logger.info(f"ğŸ“š è·å–å†å²å¯¹è¯è®°å½•ï¼Œå…± {len(conversation_history)} æ¡æ¶ˆæ¯")
            
            # ğŸ¯ æ­¥éª¤1: è§„åˆ’é˜¶æ®µ
            yield {
                "type": "planning_start",
                "message": "ğŸ§  æ­£åœ¨åˆ†æé—®é¢˜å¹¶åˆ¶å®šæ‰§è¡Œè®¡åˆ’..."
            }
            
            # ä¼ é€’å†å²å¯¹è¯ç»™è§„åˆ’å™¨
            plan = await self.planner.create_plan(message, user_info, conversation_history)
            
            # è·å–ä»»åŠ¡åˆ—è¡¨ï¼ˆä¼˜å…ˆä½¿ç”¨tasksï¼Œå¦åˆ™ä½¿ç”¨expertsï¼‰
            tasks = plan.get("tasks", [])
            if not tasks:
                # å‘åå…¼å®¹ï¼šå¦‚æœæ²¡æœ‰tasksï¼Œä»expertsåˆ›å»ºç®€å•ä»»åŠ¡
                expert_names = plan.get("experts", [])
                tasks = [{"expert": name, "task_description": f"æ‰§è¡Œ{name}çš„æ ‡å‡†èŒè´£"} for name in expert_names]
            
            yield {
                "type": "plan_created",
                "plan": plan,
                "tasks": tasks,
                "reasoning": plan.get("reasoning", ""),
                "message": f"ğŸ“‹ æ‰§è¡Œè®¡åˆ’ï¼šå°†ä¾æ¬¡æ‰§è¡Œ {len(tasks)} ä¸ªä»»åŠ¡"
            }
            
            # ğŸ¯ æ­¥éª¤2: å‡†å¤‡æ‰§è¡Œä¸Šä¸‹æ–‡
            
            context = {
                "user_id": user_id,
                "user_question": message,
                "user_info": user_info,
                "conversation_history": conversation_history  # æ·»åŠ å†å²å¯¹è¯è®°å½•
            }
            
            # ğŸ¯ æ­¥éª¤3: æ‰§è¡Œé˜¶æ®µ
            expert_results = []
            
            for i, task in enumerate(tasks):
                expert_name = task.get("expert")
                task_description = task.get("task_description", "")
                
                # å‘é€ä¸“å®¶å¼€å§‹ä¿¡æ¯ï¼ˆåŒ…å«ä»»åŠ¡æè¿°ï¼‰
                yield {
                    "type": "expert_start",
                    "expert": expert_name,
                    "task_description": task_description,
                    "step": i + 1,
                    "total": len(tasks),
                    "message": f"ğŸ¤– [{i+1}/{len(tasks)}] æ­£åœ¨å’¨è¯¢ {expert_name}..."
                }
                
                # è·å–ä¸“å®¶å¹¶æ‰§è¡Œ
                expert = self.executor.experts.get(expert_name)
                if not expert:
                    logger.warning(f"ä¸“å®¶ {expert_name} ä¸å­˜åœ¨")
                    continue
                
                # å°†ä»»åŠ¡æè¿°æ·»åŠ åˆ°ä¸Šä¸‹æ–‡
                context["assigned_task"] = task_description
                context["task_index"] = i + 1
                context["total_tasks"] = len(tasks)
                
                # æ‰§è¡Œä¸“å®¶ä»»åŠ¡
                result = await expert.process(context)
                expert_results.append(result)
                
                # ç”Ÿæˆä»»åŠ¡å®Œæˆæ±‡æŠ¥
                completion_report = self.executor._generate_completion_report(expert_name, task_description, result)
                
                # å‘é€ä¸“å®¶å®Œæˆä¿¡æ¯å’Œç»“æœ
                if result.get("success"):
                    # æå–ä¸“å®¶çš„åˆ†æå†…å®¹
                    expert_content = (
                        result.get("analysis") or 
                        result.get("explanation") or 
                        result.get("recommendation") or
                        result.get("final_response") or
                        ""
                    )
                    
                    # æ„å»ºå®Œæ•´çš„ä¸“å®¶ç»“æœï¼ŒåŒ…å«æ‰€æœ‰ç›¸å…³ä¿¡æ¯
                    expert_result_data = {
                        "success": True,
                        "content": expert_content,  # å®Œæ•´å†…å®¹ï¼Œä¸æˆªæ–­
                        "expert_name": expert.name,
                        "expert_type": expert_name,
                        "assigned_task": task_description,  # åˆ†é…çš„ä»»åŠ¡
                        "completion_report": completion_report  # å®Œæˆæ±‡æŠ¥
                    }
                    
                    # æ·»åŠ æ•°æ®ä¸“å®¶çš„æ•°æ®
                    if expert_name == "DataExpert" and result.get("data"):
                        expert_result_data["data"] = result.get("data")
                        expert_result_data["mcp_tool"] = "query_user_health_records"
                    
                    # æ·»åŠ çŸ¥è¯†ä¸“å®¶çš„çŸ¥è¯†åº“å†…å®¹
                    if expert_name == "KnowledgeExpert" and result.get("knowledge"):
                        expert_result_data["knowledge"] = result.get("knowledge")
                        expert_result_data["mcp_tool"] = "search_diabetes_knowledge"
                    
                    # æ·»åŠ åŒ»ç”Ÿæ¨èä¸“å®¶çš„åŒ»ç”Ÿåˆ—è¡¨
                    if expert_name == "DoctorExpert" and result.get("doctors"):
                        expert_result_data["doctors"] = result.get("doctors")
                        expert_result_data["mcp_tool"] = "query_doctor_list"
                    
                    # æ·»åŠ æ•°æ®è®°å½•ä¸“å®¶çš„ç»“æœ
                    if expert_name == "DataRecordExpert":
                        expert_result_data["has_new_data"] = result.get("has_new_data", False)
                        expert_result_data["records_added"] = result.get("records_added", [])
                        expert_result_data["parsed_data"] = result.get("parsed_data", [])
                    
                    # æ·»åŠ é—®è¯Šä¸“å®¶çš„è¯„ä¼°ç»“æœ
                    if expert_name == "ConsultationExpert":
                        expert_result_data["info_sufficient"] = result.get("info_sufficient", True)
                        expert_result_data["questions"] = result.get("questions", [])
                        expert_result_data["reason"] = result.get("reason", "")
                        expert_result_data["assessment"] = result.get("assessment", {})
                        # æ·»åŠ é—®è¯Šä¸“å®¶çš„MCPè°ƒç”¨ç»“æœ
                        if result.get("health_records"):
                            expert_result_data["data"] = result.get("health_records")
                            expert_result_data["mcp_tool"] = "query_user_health_records"
                        if result.get("knowledge"):
                            expert_result_data["knowledge"] = result.get("knowledge")
                            expert_result_data["mcp_tool"] = "search_diabetes_knowledge"
                    
                    # æ·»åŠ MCPè°ƒç”¨è¯¦æƒ…
                    if result.get("mcp_calls"):
                        expert_result_data["mcp_calls"] = result.get("mcp_calls")
                    
                    # æ·»åŠ å…¶ä»–å¯èƒ½çš„å­—æ®µ
                    for key in ["confidence", "data", "knowledge", "doctors", "info_sufficient", "questions", "reason", "has_new_data", "records_added", "mcp_calls"]:
                        if key in result and key not in expert_result_data:
                            expert_result_data[key] = result[key]
                    
                    # å‡†å¤‡å‘é€çš„æ¶ˆæ¯
                    complete_message = {
                        "type": "expert_complete",
                        "expert": expert_name,
                        "result": expert_result_data,
                        "message": f"âœ… {expert.name} åˆ†æå®Œæˆ"
                    }
                    
                    # å¦‚æœæœ‰ ReAct ä¿¡æ¯ï¼Œæ·»åŠ åˆ°æ¶ˆæ¯ä¸­
                    if result.get("react_mode") and result.get("steps"):
                        complete_message["react_info"] = {
                            "iterations": result.get("iterations", 0),
                            "goal_achieved": result.get("goal_achieved", False),
                            "steps": result.get("steps", [])
                        }
                    
                    yield complete_message
                    
                    # å¦‚æœæ˜¯ç»¼åˆä¸“å®¶ï¼Œæµå¼è¾“å‡ºæœ€ç»ˆå›å¤
                    if expert_name == "SynthesisExpert":
                        final_response = result.get("final_response", "")
                        
                        # æµå¼å‘é€æœ€ç»ˆå›å¤
                        yield {
                            "type": "final_response_start",
                            "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›å¤..."
                        }
                        
                        # åˆ†å—å‘é€
                        chunk_size = 20
                        for j in range(0, len(final_response), chunk_size):
                            chunk = final_response[j:j + chunk_size]
                            yield {
                                "type": "final_content",
                                "content": chunk
                            }
                    
                else:
                    yield {
                        "type": "expert_error",
                        "expert": expert_name,
                        "error": result.get("error", "æœªçŸ¥é”™è¯¯")
                    }
                
                # æ›´æ–°ä¸Šä¸‹æ–‡
                if expert_name == "DiagnosisExpert":
                    context["diagnosis_result"] = result
                elif expert_name == "DataExpert":
                    context["health_data"] = result.get("data", {})
                elif expert_name == "KnowledgeExpert":
                    context["knowledge"] = result.get("knowledge", {})
                elif expert_name == "DoctorExpert":
                    context["doctor_recommendation"] = result
                elif expert_name == "DataRecordExpert":
                    # æ•°æ®è®°å½•ä¸“å®¶æ›´æ–°ä¸Šä¸‹æ–‡
                    if result.get("has_new_data"):
                        logger.info(f"ğŸ“ ç”¨æˆ·æä¾›äº†æ–°æ•°æ®ï¼Œå·²è®°å½•åˆ°ç³»ç»Ÿ")
                elif expert_name == "ConsultationExpert":
                    # ğŸš¨ å…³é”®ï¼šå¦‚æœé—®è¯Šä¸“å®¶åˆ¤æ–­ä¿¡æ¯ä¸è¶³ï¼ŒåŠ¨æ€è°ƒæ•´è®¡åˆ’
                    if not result.get("info_sufficient", True):
                        logger.info(f"âš ï¸ é—®è¯Šä¸“å®¶åˆ¤æ–­ä¿¡æ¯ä¸è¶³ï¼Œè·³è¿‡å…¶ä»–ä¸“å®¶ï¼Œç›´æ¥ç»¼åˆå›å¤")
                        # åªä¿ç•™ç»¼åˆä¸“å®¶
                        context["expert_results"] = expert_results
                        # ç›´æ¥è·³åˆ°ç»¼åˆä¸“å®¶
                        synthesis_expert = self.executor.experts.get("SynthesisExpert")
                        if synthesis_expert:
                            # å‘é€ç»¼åˆä¸“å®¶å¼€å§‹
                            yield {
                                "type": "expert_start",
                                "expert": "SynthesisExpert",
                                "step": len(expert_results) + 1,
                                "total": len(expert_results) + 1,
                                "message": "ğŸ”„ æ­£åœ¨æ•´åˆæ„è§å¹¶ç”Ÿæˆå›å¤..."
                            }
                            
                            # æ‰§è¡Œç»¼åˆä¸“å®¶
                            synthesis_result = await synthesis_expert.process(context)
                            expert_results.append(synthesis_result)
                            
                            # å‘é€ç»¼åˆä¸“å®¶å®Œæˆ
                            if synthesis_result.get("success"):
                                final_response = synthesis_result.get("final_response", "")
                                yield {
                                    "type": "expert_complete",
                                    "expert": "SynthesisExpert",
                                    "result": {
                                        "success": True,
                                        "content": final_response,
                                        "expert_name": "ç»¼åˆä¸“å®¶",
                                        "expert_type": "SynthesisExpert"
                                    },
                                    "message": "âœ… ç»¼åˆä¸“å®¶åˆ†æå®Œæˆ"
                                }
                                
                                # æµå¼è¾“å‡ºæœ€ç»ˆå›å¤
                                yield {"type": "final_response_start", "message": "æ­£åœ¨ç”Ÿæˆæœ€ç»ˆå›å¤..."}
                                chunk_size = 20
                                for j in range(0, len(final_response), chunk_size):
                                    yield {"type": "final_content", "content": final_response[j:j + chunk_size]}
                        
                        # è·³å‡ºå¾ªç¯ï¼Œä¸å†æ‰§è¡Œåç»­ä¸“å®¶
                        break
                elif expert_name == "SynthesisExpert":
                    context["expert_results"] = expert_results[:-1]
            
            # ğŸ¯ æ­¥éª¤4: ä¿å­˜æœ€ç»ˆå›å¤å’Œä¸“å®¶è®¡åˆ’
            final_result = expert_results[-1] if expert_results else {}
            final_response = final_result.get("final_response", "æŠ±æ­‰ï¼Œæš‚æ—¶æ— æ³•ç”Ÿæˆå›å¤ã€‚")
            
            # æ„å»ºå®Œæ•´çš„expert_planæ•°æ®ï¼ŒåŒ…å«æ¯ä¸ªä¸“å®¶çš„æ‰§è¡Œç»“æœå’Œæ–°çš„ä»»åŠ¡ä¿¡æ¯
            expert_plan_data = {
                "plan": plan,
                "tasks": tasks,  # æ–°å¢ï¼šä»»åŠ¡åˆ—è¡¨
                "reasoning": plan.get("reasoning", ""),  # æ–°å¢ï¼šè®¡åˆ’æ¨ç†
                "experts": []
            }
            
            # æ”¶é›†æ¯ä¸ªä¸“å®¶çš„æ‰§è¡Œç»“æœ
            for i, result in enumerate(expert_results):
                expert_name = result.get("expert", "Unknown")
                
                # ä¸ºä¿æŒä¸WebSocketäº‹ä»¶ä¸€è‡´ï¼Œæå–å†…å®¹å¹¶æ·»åŠ contentå­—æ®µ
                expert_content = (
                    result.get("analysis") or 
                    result.get("explanation") or 
                    result.get("recommendation") or
                    result.get("final_response") or
                    ""
                )
                
                # åˆ›å»ºresultå‰¯æœ¬å¹¶æ·»åŠ æ–°å­—æ®µï¼ˆä¸WebSocketäº‹ä»¶ä¿æŒä¸€è‡´ï¼‰
                result_with_content = dict(result)  # å¤åˆ¶åŸå§‹result
                result_with_content["content"] = expert_content  # æ·»åŠ contentå­—æ®µ
                
                # æ·»åŠ ä»»åŠ¡åˆ†é…å’Œå®Œæˆæ±‡æŠ¥ä¿¡æ¯
                if result.get("assigned_task"):
                    result_with_content["assigned_task"] = result["assigned_task"]
                if result.get("completion_report"):
                    result_with_content["completion_report"] = result["completion_report"]
                
                expert_data = {
                    "name": expert_name,
                    "success": result.get("success", False),
                    "result": result_with_content  # ä½¿ç”¨åŒ…å«æ–°å­—æ®µçš„result
                }
                expert_plan_data["experts"].append(expert_data)
            
            await self.session_manager.add_message(
                user_id,
                "assistant",
                final_response,
                tool_calls=None,
                thinking=f"æ‰§è¡Œè®¡åˆ’ï¼š{plan.get('reasoning', '')}",
                expert_plan=expert_plan_data
            )
            
            # å‘é€å®Œæˆä¿¡å·
            yield {
                "type": "complete",
                "message": "âœ… å¤„ç†å®Œæˆ",
                "expert_count": len(expert_results)
            }
            
        except Exception as e:
            logger.error(f"å¤šä¸“å®¶å¤„ç†å¤±è´¥: {e}", exc_info=True)
            yield {
                "type": "error",
                "error": str(e)
            } 