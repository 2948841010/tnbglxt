#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç³–å°¿ç—…çŸ¥è¯†åº“å‘é‡æ£€ç´¢æµ‹è¯•è„šæœ¬
æµ‹è¯•ChromaDBæ•°æ®åº“çš„æ£€ç´¢åŠŸèƒ½å’Œæ€§èƒ½
"""

import time
import json
from typing import List, Dict, Any, Optional
import logging
from pathlib import Path

import torch
import numpy as np
from sentence_transformers import SentenceTransformer
import chromadb
from chromadb.config import Settings

# é…ç½®æ—¥å¿—
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

class DiabetesRAGTester:
    """ç³–å°¿ç—…çŸ¥è¯†åº“RAGæ£€ç´¢æµ‹è¯•å™¨"""
    
    def __init__(self, 
                 model_path: str = "data/models/AI-ModelScope/bge-large-zh-v1___5",
                 db_path: str = "chroma_db",
                 collection_name: str = "diabetes_knowledge",
                 use_gpu: bool = True):
        
        self.model_path = model_path
        self.db_path = Path(db_path)
        self.collection_name = collection_name
        self.use_gpu = use_gpu and torch.cuda.is_available()
        
        # åˆå§‹åŒ–
        self.model = None
        self.client = None
        self.collection = None
        
        logger.info(f"åˆå§‹åŒ–RAGæ£€ç´¢æµ‹è¯•å™¨")
        logger.info(f"GPUæ”¯æŒ: {'âœ… å¯ç”¨' if self.use_gpu else 'âŒ ç¦ç”¨'}")
    
    def load_model_and_db(self):
        """åŠ è½½æ¨¡å‹å’Œæ•°æ®åº“"""
        print("ğŸ”„ åˆå§‹åŒ–æ¨¡å‹å’Œæ•°æ®åº“...")
        
        # åŠ è½½BGEæ¨¡å‹
        try:
            device = 'cuda' if self.use_gpu else 'cpu'
            print(f"ğŸ“± åŠ è½½BGEæ¨¡å‹åˆ° {device}...")
            start_time = time.time()
            
            self.model = SentenceTransformer(self.model_path, device=device)
            
            load_time = time.time() - start_time
            print(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ! ç”¨æ—¶: {load_time:.2f}ç§’")
            
            if self.use_gpu:
                memory_allocated = torch.cuda.memory_allocated() / (1024**2)
                print(f"ğŸ’¾ GPUå†…å­˜ä½¿ç”¨: {memory_allocated:.1f}MB")
            
        except Exception as e:
            print(f"âŒ æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
            return False
        
        # è¿æ¥ChromaDB
        try:
            print("ğŸ”— è¿æ¥ChromaDBæ•°æ®åº“...")
            self.client = chromadb.PersistentClient(
                path=str(self.db_path),
                settings=Settings(anonymized_telemetry=False)
            )
            
            self.collection = self.client.get_collection(self.collection_name)
            
            count = self.collection.count()
            print(f"âœ… æ•°æ®åº“è¿æ¥æˆåŠŸ! æ€»è®°å½•æ•°: {count}")
            
        except Exception as e:
            print(f"âŒ æ•°æ®åº“è¿æ¥å¤±è´¥: {e}")
            return False
        
        return True
    
    def search_knowledge(self, query: str, top_k: int = 5, similarity_threshold: float = 0.0) -> Dict[str, Any]:
        """æ‰§è¡ŒçŸ¥è¯†æ£€ç´¢"""
        try:
            start_time = time.time()
            
            # å‘é‡åŒ–æŸ¥è¯¢
            query_start = time.time()
            query_embedding = self.model.encode([query], normalize_embeddings=True)
            query_time = time.time() - query_start
            
            # æ‰§è¡Œæ£€ç´¢
            search_start = time.time()
            results = self.collection.query(
                query_embeddings=query_embedding.tolist(),
                n_results=top_k,
                include=['documents', 'metadatas', 'distances']
            )
            search_time = time.time() - search_start
            
            total_time = time.time() - start_time
            
            # å¤„ç†ç»“æœ
            processed_results = []
            if results['documents'] and results['documents'][0]:
                for i, (doc, metadata, distance) in enumerate(zip(
                    results['documents'][0],
                    results['metadatas'][0], 
                    results['distances'][0]
                )):
                    similarity = 1 - distance
                    if similarity >= similarity_threshold:
                        processed_results.append({
                            'rank': i + 1,
                            'question': metadata['question'],
                            'answer': doc,
                            'category': metadata['category'],
                            'similarity': similarity,
                            'distance': distance,
                            'entities': json.loads(metadata.get('entities', '[]'))
                        })
            
            return {
                'success': True,
                'query': query,
                'results': processed_results,
                'performance': {
                    'query_time': query_time,
                    'search_time': search_time,
                    'total_time': total_time,
                    'results_count': len(processed_results)
                }
            }
            
        except Exception as e:
            return {
                'success': False,
                'query': query,
                'error': str(e),
                'results': [],
                'performance': {}
            }
    
    def run_predefined_tests(self):
        """è¿è¡Œé¢„å®šä¹‰æµ‹è¯•ç”¨ä¾‹"""
        print("\n" + "="*80)
        print("ğŸ§ª è¿è¡Œé¢„å®šä¹‰æµ‹è¯•ç”¨ä¾‹")
        print("="*80)
        
        test_cases = [
            {
                'name': 'ç—‡çŠ¶æŸ¥è¯¢',
                'query': 'ç³–å°¿ç—…æœ‰ä»€ä¹ˆç—‡çŠ¶ï¼Ÿ',
                'expected_categories': ['åŸºç¡€çŸ¥è¯†', 'å…¶ä»–']
            },
            {
                'name': 'å¹¶å‘ç—‡æŸ¥è¯¢',
                'query': 'ç³–å°¿ç—…è§†ç½‘è†œç—…å˜æ€ä¹ˆæ²»ç–—ï¼Ÿ',
                'expected_categories': ['çœ¼éƒ¨ç–¾ç—…', 'æ²»ç–—æ–¹æ³•']
            },
            {
                'name': 'æ²»ç–—æ–¹æ³•æŸ¥è¯¢',
                'query': 'å¦‚ä½•æ§åˆ¶è¡€ç³–ï¼Ÿ',
                'expected_categories': ['æ²»ç–—æ–¹æ³•', 'åŸºç¡€çŸ¥è¯†']
            },
            {
                'name': 'è¯Šæ–­æ£€æŸ¥æŸ¥è¯¢',
                'query': 'ç³–å°¿ç—…éœ€è¦åšä»€ä¹ˆæ£€æŸ¥ï¼Ÿ',
                'expected_categories': ['è¯Šæ–­æ£€æŸ¥', 'åŸºç¡€çŸ¥è¯†']
            },
            {
                'name': 'ç¥ç»å¹¶å‘ç—‡æŸ¥è¯¢',
                'query': 'ç³–å°¿ç—…ç¥ç»ç—…å˜çš„ç—‡çŠ¶',
                'expected_categories': ['ç¥ç»ç–¾ç—…']
            },
            {
                'name': 'æ¨¡ç³ŠæŸ¥è¯¢',
                'query': 'çœ¼ç›çœ‹ä¸æ¸…æ¥š',
                'expected_categories': ['çœ¼éƒ¨ç–¾ç—…']
            }
        ]
        
        all_results = []
        total_time = 0
        
        for i, test_case in enumerate(test_cases, 1):
            print(f"\n--- æµ‹è¯• {i}: {test_case['name']} ---")
            print(f"æŸ¥è¯¢: {test_case['query']}")
            
            result = self.search_knowledge(test_case['query'], top_k=3)
            all_results.append(result)
            
            if result['success']:
                perf = result['performance']
                total_time += perf['total_time']
                
                print(f"â±ï¸  æ£€ç´¢ç”¨æ—¶: {perf['total_time']:.3f}ç§’ (æŸ¥è¯¢: {perf['query_time']:.3f}s, æœç´¢: {perf['search_time']:.3f}s)")
                print(f"ğŸ“Š æ‰¾åˆ°ç»“æœ: {perf['results_count']} æ¡")
                
                if result['results']:
                    print("ğŸ¯ æ£€ç´¢ç»“æœ:")
                    for j, res in enumerate(result['results'], 1):
                        print(f"  {j}. [{res['category']}] {res['question']} (ç›¸ä¼¼åº¦: {res['similarity']:.4f})")
                        print(f"     ç­”æ¡ˆ: {res['answer'][:100]}...")
                    
                    # æ£€æŸ¥åˆ†ç±»åŒ¹é…
                    found_categories = [res['category'] for res in result['results']]
                    expected = test_case['expected_categories']
                    category_match = any(cat in found_categories for cat in expected)
                    
                    if category_match:
                        print("âœ… åˆ†ç±»åŒ¹é…é¢„æœŸ")
                    else:
                        print(f"âš ï¸  åˆ†ç±»ä¸åŒ¹é…ã€‚æœŸæœ›: {expected}, å®é™…: {found_categories}")
                else:
                    print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
            else:
                print(f"âŒ æ£€ç´¢å¤±è´¥: {result['error']}")
        
        # æ€§èƒ½ç»Ÿè®¡
        print(f"\nğŸ“ˆ æ€»ä½“æ€§èƒ½ç»Ÿè®¡:")
        print(f"   æ€»æµ‹è¯•ç”¨ä¾‹: {len(test_cases)}")
        print(f"   æˆåŠŸæµ‹è¯•: {len([r for r in all_results if r['success']])}")
        print(f"   æ€»æ£€ç´¢æ—¶é—´: {total_time:.3f}ç§’")
        print(f"   å¹³å‡æ£€ç´¢æ—¶é—´: {total_time/len(test_cases):.3f}ç§’")
        
        return all_results
    
    def interactive_test(self):
        """äº¤äº’å¼æµ‹è¯•"""
        print("\n" + "="*80)
        print("ğŸ” äº¤äº’å¼æ£€ç´¢æµ‹è¯•")
        print("="*80)
        print("è¾“å…¥æŸ¥è¯¢é—®é¢˜ï¼Œè¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
        
        while True:
            try:
                query = input("\nè¯·è¾“å…¥æŸ¥è¯¢: ").strip()
                
                if query.lower() in ['quit', 'exit', 'é€€å‡º', 'q']:
                    print("ğŸ‘‹ æµ‹è¯•ç»“æŸï¼")
                    break
                
                if not query:
                    print("è¯·è¾“å…¥æœ‰æ•ˆæŸ¥è¯¢")
                    continue
                
                print(f"\nğŸ” æœç´¢: {query}")
                result = self.search_knowledge(query, top_k=5)
                
                if result['success']:
                    perf = result['performance']
                    print(f"â±ï¸  æ£€ç´¢ç”¨æ—¶: {perf['total_time']:.3f}ç§’")
                    print(f"ğŸ“Š æ‰¾åˆ°ç»“æœ: {perf['results_count']} æ¡")
                    
                    if result['results']:
                        print("\nğŸ¯ æ£€ç´¢ç»“æœ:")
                        for i, res in enumerate(result['results'], 1):
                            print(f"\n{i}. ç›¸ä¼¼åº¦: {res['similarity']:.4f}")
                            print(f"   åˆ†ç±»: {res['category']}")
                            print(f"   é—®é¢˜: {res['question']}")
                            print(f"   ç­”æ¡ˆ: {res['answer']}")
                            if res['entities']:
                                print(f"   å®ä½“: {', '.join(res['entities'])}")
                    else:
                        print("âŒ æœªæ‰¾åˆ°ç›¸å…³ç»“æœ")
                        print("ğŸ’¡ å°è¯•ä½¿ç”¨ä¸åŒçš„å…³é”®è¯æˆ–æ›´å…·ä½“çš„é—®é¢˜")
                else:
                    print(f"âŒ æ£€ç´¢å¤±è´¥: {result['error']}")
                    
            except KeyboardInterrupt:
                print("\nğŸ‘‹ æµ‹è¯•ç»“æŸï¼")
                break
            except Exception as e:
                print(f"âŒ æµ‹è¯•å‡ºé”™: {e}")
    
    def benchmark_test(self, num_queries: int = 50):
        """æ€§èƒ½åŸºå‡†æµ‹è¯•"""
        print(f"\n" + "="*80)
        print(f"ğŸš€ æ€§èƒ½åŸºå‡†æµ‹è¯• (æ‰§è¡Œ {num_queries} æ¬¡æŸ¥è¯¢)")
        print("="*80)
        
        # å‡†å¤‡æµ‹è¯•æŸ¥è¯¢
        test_queries = [
            "ç³–å°¿ç—…ç—‡çŠ¶", "è¡€ç³–æ§åˆ¶", "è§†ç½‘è†œç—…å˜", "èƒ°å²›ç´ æ²»ç–—", "å¹¶å‘ç—‡",
            "ç¥ç»ç—…å˜", "è‚¾ç—…", "çœ¼ç—…", "é¥®é£Ÿæ§åˆ¶", "è¿åŠ¨ç–—æ³•",
            "è¡€ç³–ç›‘æµ‹", "è¯ç‰©æ²»ç–—", "ä½è¡€ç³–", "é«˜è¡€ç³–", "ç³–å°¿ç—…æ£€æŸ¥",
            "ç³–å°¿ç—…åˆ†ç±»", "1å‹ç³–å°¿ç—…", "2å‹ç³–å°¿ç—…", "å¦Šå¨ ç³–å°¿ç—…", "ç³–å°¿ç—…è¯Šæ–­"
        ]
        
        # æ‰©å±•æŸ¥è¯¢åˆ°æŒ‡å®šæ•°é‡
        extended_queries = (test_queries * ((num_queries // len(test_queries)) + 1))[:num_queries]
        
        print(f"ğŸ“‹ å¼€å§‹æ‰§è¡Œ {len(extended_queries)} æ¬¡æ£€ç´¢...")
        
        times = []
        successful_queries = 0
        
        start_time = time.time()
        
        for i, query in enumerate(extended_queries, 1):
            if i % 10 == 0:
                print(f"è¿›åº¦: {i}/{num_queries}")
            
            result = self.search_knowledge(query, top_k=3)
            
            if result['success']:
                times.append(result['performance']['total_time'])
                successful_queries += 1
        
        total_time = time.time() - start_time
        
        if times:
            avg_time = np.mean(times)
            min_time = np.min(times)
            max_time = np.max(times)
            std_time = np.std(times)
            
            print(f"\nğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•ç»“æœ:")
            print(f"   æ€»æŸ¥è¯¢æ•°: {num_queries}")
            print(f"   æˆåŠŸæŸ¥è¯¢: {successful_queries}")
            print(f"   æˆåŠŸç‡: {successful_queries/num_queries*100:.1f}%")
            print(f"   æ€»æ—¶é—´: {total_time:.3f}ç§’")
            print(f"   å¹³å‡å“åº”æ—¶é—´: {avg_time:.3f}ç§’")
            print(f"   æœ€å¿«å“åº”: {min_time:.3f}ç§’")
            print(f"   æœ€æ…¢å“åº”: {max_time:.3f}ç§’")
            print(f"   å“åº”æ—¶é—´æ ‡å‡†å·®: {std_time:.3f}ç§’")
            print(f"   QPS (æ¯ç§’æŸ¥è¯¢æ•°): {successful_queries/total_time:.1f}")
            
            # å“åº”æ—¶é—´åˆ†å¸ƒ
            fast_queries = len([t for t in times if t < 0.05])
            medium_queries = len([t for t in times if 0.05 <= t < 0.1])
            slow_queries = len([t for t in times if t >= 0.1])
            
            print(f"\nğŸ“ˆ å“åº”æ—¶é—´åˆ†å¸ƒ:")
            print(f"   < 50ms: {fast_queries} æ¬¡ ({fast_queries/len(times)*100:.1f}%)")
            print(f"   50-100ms: {medium_queries} æ¬¡ ({medium_queries/len(times)*100:.1f}%)")
            print(f"   > 100ms: {slow_queries} æ¬¡ ({slow_queries/len(times)*100:.1f}%)")
        
        return {
            'total_queries': num_queries,
            'successful_queries': successful_queries,
            'success_rate': successful_queries/num_queries if num_queries > 0 else 0,
            'total_time': total_time,
            'average_time': avg_time if times else 0,
            'min_time': min_time if times else 0,
            'max_time': max_time if times else 0,
            'qps': successful_queries/total_time if total_time > 0 else 0
        }

def main():
    """ä¸»å‡½æ•°"""
    print("="*80)
    print("ğŸ” ç³–å°¿ç—…çŸ¥è¯†åº“RAGæ£€ç´¢æµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºæµ‹è¯•å™¨
    tester = DiabetesRAGTester(
        model_path="data/models/AI-ModelScope/bge-large-zh-v1___5",
        db_path="chroma_db",
        collection_name="diabetes_knowledge",
        use_gpu=True
    )
    
    # åˆå§‹åŒ–
    if not tester.load_model_and_db():
        print("âŒ åˆå§‹åŒ–å¤±è´¥ï¼Œé€€å‡ºæµ‹è¯•")
        return False
    
    try:
        while True:
            print(f"\n{'='*60}")
            print("ğŸ› ï¸  æµ‹è¯•é€‰é¡¹:")
            print("1. è¿è¡Œé¢„å®šä¹‰æµ‹è¯•ç”¨ä¾‹")
            print("2. äº¤äº’å¼æ£€ç´¢æµ‹è¯•")
            print("3. æ€§èƒ½åŸºå‡†æµ‹è¯•")
            print("4. é€€å‡º")
            print("="*60)
            
            choice = input("è¯·é€‰æ‹©æµ‹è¯•ç±»å‹ (1-4): ").strip()
            
            if choice == '1':
                tester.run_predefined_tests()
            elif choice == '2':
                tester.interactive_test()
            elif choice == '3':
                num_queries = input("è¯·è¾“å…¥æµ‹è¯•æŸ¥è¯¢æ•°é‡ (é»˜è®¤50): ").strip()
                num_queries = int(num_queries) if num_queries.isdigit() else 50
                tester.benchmark_test(num_queries)
            elif choice == '4':
                print("ğŸ‘‹ æµ‹è¯•ç»“æŸï¼")
                break
            else:
                print("âŒ æ— æ•ˆé€‰æ‹©ï¼Œè¯·è¾“å…¥ 1-4")
                
    except KeyboardInterrupt:
        print("\nğŸ‘‹ æµ‹è¯•ç»“æŸï¼")
    finally:
        # æ¸…ç†GPUå†…å­˜
        if torch.cuda.is_available():
            torch.cuda.empty_cache()
    
    return True

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1) 